{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.6 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "fbbb7d2143a1d68e1cf272edf0974e702b621cb99b4ee39ce84db3bf0ffb588e"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tweets_list,columns=['ID', 'FULL TEXT', 'CREATED AT'])\n",
      "except BaseException as e:\n",
      "    print('failed on_status,',str(e))\n",
      "    time.sleep(3)\n",
      "tweets_df.to_csv('sinhala_tweets.csv',index=False)\n",
      "518/27: df.to_csv('sinhala-tweets-v0', encoding=\"utf-8\",index=False)\n",
      "518/28: tweets_df.head(n=10)\n",
      "518/29: tweets_df.head(n=10)\n",
      "518/30: tweets_df.head(n=10)\n",
      "518/31: df.to_csv('sinhala-tweets-v0.csv', encoding=\"utf-8\",index=False)\n",
      "518/32:\n",
      "api = connect_to_twitter()\n",
      "text_query = 'SriLanka OR lk OR LK OR srilanka OR shame OR Shame OR LKA OR hate OR sad OR SL OR sl -filter:retweets'\n",
      "try:\n",
      "    tweets = tweepy.Cursor(api.search,q=text_query,lang=\"si\",tweet_mode='extended').items(4000)\n",
      "    # create a dataframe from the existing information\n",
      "    tweets_list = [[ tweet.id_str, tweet.full_text, tweet.created_at] for tweet in tweets]\n",
      "    df = pd.DataFrame(tweets_list,columns=['ID', 'FULL TEXT', 'CREATED AT'])\n",
      "except BaseException as e:\n",
      "    print('failed on_status,',str(e))\n",
      "    time.sleep(3)\n",
      "518/33: df.to_csv('sinhala-tweets-v2.csv', encoding=\"utf-8\",index=False)\n",
      "518/34: len(df)\n",
      "518/35:\n",
      "api = connect_to_twitter()\n",
      "query = \"උන් OR උං OR සමහර OR අතරින් OR නැත්තම් OR මතකය OR තම්බි OR බැගින් OR බැඟින් OR රකින්න OR නියමයි OR අදහස OR මුලු OR මුළු OR අධික OR පනින්න OR එයලව OR ආවාහම OR හට OR මෙන් OR අපරාදේ OR විනාශය OR විනාෂය OR රට OR අන්තවාදය OR හුත්ත OR පුක OR තමුසේ OR තමුසෙ OR තමුසෙලා OR ඔයි OR මිනිස්සු OR ඔයී OR කුනු OR කුණු -filter:retweets\"\n",
      "try:\n",
      "    tweets = tweepy.Cursor(api.search,q=query,lang=\"si\", tweet_mode='extended').items(5000)\n",
      "    # create a dataframe from the existing information\n",
      "    tweets_list = [[ tweet.id_str, tweet.full_text, tweet.created_at] for tweet in tweets)]\n",
      "    df = pd.DataFrame(tweets_list,columns=['ID', 'FULL TEXT', 'CREATED AT'])\n",
      "except BaseException as e:\n",
      "    print('failed on_status,',str(e))\n",
      "    time.sleep(3)\n",
      "tweets_df.to_csv('sinhala_tweets-v3.csv',index=False)\n",
      "518/36:\n",
      "api = connect_to_twitter()\n",
      "query = \"උන් OR උං OR සමහර OR අතරින් OR නැත්තම් OR මතකය OR තම්බි OR බැගින් OR බැඟින් OR රකින්න OR නියමයි OR අදහස OR මුලු OR මුළු OR අධික OR පනින්න OR එයලව OR ආවාහම OR හට OR මෙන් OR අපරාදේ OR විනාශය OR විනාෂය OR රට OR අන්තවාදය OR හුත්ත OR පුක OR තමුසේ OR තමුසෙ OR තමුසෙලා OR ඔයි OR මිනිස්සු OR ඔයී OR කුනු OR කුණු -filter:retweets\"\n",
      "try:\n",
      "    tweets = tweepy.Cursor(api.search,q=query,lang=\"si\", tweet_mode='extended').items(5000)\n",
      "    # create a dataframe from the existing information\n",
      "    tweets_list = [[ tweet.id_str, tweet.full_text, tweet.created_at] for tweet in tweets]\n",
      "    df = pd.DataFrame(tweets_list,columns=['ID', 'FULL TEXT', 'CREATED AT'])\n",
      "except BaseException as e:\n",
      "    print('failed on_status,',str(e))\n",
      "    time.sleep(3)\n",
      "tweets_df.to_csv('sinhala_tweets-v3.csv',index=False)\n",
      "518/37:\n",
      "api = connect_to_twitter()\n",
      "query = \"උන් OR උං OR සමහර OR අතරින් OR නැත්තම් OR මතකය OR තම්බි OR බැගින් OR බැඟින් OR රකින්න OR නියමයි OR අදහස OR මුලු OR මුළු OR අධික OR පනින්න OR එයලව OR ආවාහම OR හට OR මෙන් OR අපරාදේ OR විනාශය OR විනාෂය OR රට OR අන්තවාදය OR හුත්ත OR පුක OR තමුසේ OR තමුසෙ OR තමුසෙලා OR ඔයි OR මිනිස්සු OR ඔයී OR කුනු OR කුණු -filter:retweets\"\n",
      "try:\n",
      "    tweets = tweepy.Cursor(api.search,q=query,lang=\"si\", tweet_mode='extended').items(4000)\n",
      "    # create a dataframe from the existing information\n",
      "    tweets_list = [[ tweet.id_str, tweet.full_text, tweet.created_at] for tweet in tweets]\n",
      "    df = pd.DataFrame(tweets_list,columns=['ID', 'FULL TEXT', 'CREATED AT'])\n",
      "except BaseException as e:\n",
      "    print('failed on_status,',str(e))\n",
      "    time.sleep(3)\n",
      "tweets_df.to_csv('sinhala_tweets-v3.csv',encoding=\"utf-8\",index=False)\n",
      "518/38: len(tweets_df)\n",
      "518/39: tweets_df.head(n=10)\n",
      "518/40:\n",
      "api = connect_to_twitter()\n",
      "query = \"උන් OR උං OR සමහර OR අතරින් OR නැත්තම් OR මතකය OR තම්බි OR බැගින් OR බැඟින් OR රකින්න OR නියමයි OR අදහස OR මුලු OR මුළු OR අධික OR පනින්න OR එයලව OR ආවාහම OR හට OR මෙන් OR අපරාදේ OR විනාශය OR විනාෂය OR රට OR අන්තවාදය OR හුත්ත OR පුක OR තමුසේ OR තමුසෙ OR තමුසෙලා OR ඔයි OR මිනිස්සු OR ඔයී OR කුනු OR කුණු OR මුන් OR මුන්ට OR තොපි OR පරයා OR පව්කාරයා -filter:retweets\"\n",
      "try:\n",
      "    tweets = tweepy.Cursor(api.search,q=query,lang=\"si\", tweet_mode='extended').items()\n",
      "    # create a dataframe from the existing information\n",
      "    tweets_list = [[ tweet.id_str, tweet.full_text, tweet.created_at] for tweet in tweets]\n",
      "    df = pd.DataFrame(tweets_list,columns=['ID', 'FULL TEXT', 'CREATED AT'])\n",
      "except BaseException as e:\n",
      "    print('failed on_status,',str(e))\n",
      "    time.sleep(3)\n",
      "tweets_df.to_csv('sinhala_tweets-v3.csv',encoding=\"utf-8\",index=False)\n",
      "518/41:\n",
      "api = connect_to_twitter()\n",
      "query = \"තම්බි\"\n",
      "try:\n",
      "    tweets = tweepy.Cursor(api.search,q=query,lang=\"si\", tweet_mode='extended').items()\n",
      "    # create a dataframe from the existing information\n",
      "    tweets_list = [[ tweet.id_str, tweet.full_text, tweet.created_at] for tweet in tweets]\n",
      "    df = pd.DataFrame(tweets_list,columns=['ID', 'FULL TEXT', 'CREATED AT'])\n",
      "except BaseException as e:\n",
      "    print('failed on_status,',str(e))\n",
      "    time.sleep(3)\n",
      "tweets_df.to_csv('sinhala_tweets-v3.csv',encoding=\"utf-8\",index=False)\n",
      "518/42: len(tweets_df)\n",
      "522/1:\n",
      "import nltk\n",
      "file0=nltk.corpus.gutenberg.fileids()[0]\n",
      "emmatext=nltk.corpus.gutenberg.raw(file0)\n",
      "emmatokens=nltk.wordpunct_tokenize(emmatext)\n",
      "print(\"emma tokens -\", emmatokens[:100])\n",
      "emmawords=[w.lower() for w in emmatokens]\n",
      "print(\"emma words- \",emmawords[:100])\n",
      "522/2:\n",
      "# stemmer work with regular case grammar\n",
      "emmaRegStem = [porter.stem(t) for t in emmatokens]\n",
      "emmaRegStem[1:100\n",
      "522/3:\n",
      "# stemmer work with regular case grammar\n",
      "emmaRegStem = [porter.stem(t) for t in emmatokens]\n",
      "emmaRegStem[1:100]\n",
      "522/4:\n",
      "# creating stemmers in nltk\n",
      "porter = nltk.PorterStemmer()\n",
      "lancaster = nltk.LancasterStemmer()\n",
      "522/5:\n",
      "# stemmer work with regular case grammar\n",
      "emmaRegStem = [porter.stem(t) for t in emmatokens]\n",
      "emmaRegStem[1:100]\n",
      "522/6:\n",
      "# stemmer work with regular case grammar\n",
      "emmaRegStem = [porter.stem(t) for t in emmatokens]\n",
      "emmaRegStem[1:50]\n",
      "522/7:\n",
      "emmaLowerStem = [porter.stem(w) for w in emmawords]\n",
      "emmaLowerStem\n",
      "522/8:\n",
      "emmaLowerStem = [porter.stem(w) for w in emmawords]\n",
      "emmaLowerStem[1:50]\n",
      "522/9:\n",
      "# stemmer work with regular case grammar for lancaster stemmer\n",
      "emmaRegStem = [lancaster.stem(t) for t in emmatokens]\n",
      "print(emmaRegStem[1:50])\n",
      "emmaLowerStem = [lancater.stem(w) for w in emmawords]\n",
      "print(emmaLowerStem[1:50])\n",
      "522/10:\n",
      "# stemmer work with regular case grammar for lancaster stemmer\n",
      "emmaRegStem = [lancaster.stem(t) for t in emmatokens]\n",
      "print(emmaRegStem[1:50])\n",
      "emmaLowerStem = [lancaster.stem(w) for w in emmawords]\n",
      "print(emmaLowerStem[1:50])\n",
      "522/11:\n",
      "# stemmer work with regular case grammar\n",
      "emmaRegStem = [porter.stem(t) for t in emmatokens]\n",
      "print(emmaRegStem[1:50])\n",
      "emmaLowerStem = [porter.stem(w) for w in emmawords]\n",
      "print(emmaLowerStem[1:50])\n",
      "522/12:\n",
      "def stem(word):\n",
      "    for suffix in ['ing','ly','ed','ious','ies','ive','es','s']:\n",
      "        if word.endswith(suffix):\n",
      "            return word[:-len(suffix)]\n",
      "    return word\n",
      "stemmedWord = stem(\"Crying\")\n",
      "522/13:\n",
      "def stem(word):\n",
      "    for suffix in ['ing','ly','ed','ious','ies','ive','es','s']:\n",
      "        if word.endswith(suffix):\n",
      "            return word[:-len(suffix)]\n",
      "    return word\n",
      "stemmedWord = stem(\"Crying\")\n",
      "stemmedWord\n",
      "522/14:\n",
      "# Lemmatization - Gives existing words unlike stemmer\n",
      "wnl = nltk.WordNetLemmatizer()\n",
      "emmaLemma = [wnl.lemmatize(t) for t in emmawords]\n",
      "emmaLemma[1:50]\n",
      "522/15:\n",
      "# Lemmatization - Gives existing words unlike stemmer\n",
      "wnl = nltk.WordNetLemmatizer()\n",
      "emmaLemma = [wnl.lemmatize(t) for t in emmawords]\n",
      "print(emmaLemma[1:50])\n",
      "522/16:\n",
      "# we can create our own word puncutation and tokenizors\n",
      "# re.match() -> any match at the beginng of stirng\n",
      "# re.search() -> anywhere in String\n",
      "# re.findall() -> substrings in anywhere of the string\n",
      "shorttext = emmatext[:150]\n",
      "import re\n",
      "pWord = re.compile(('\\w+'))\n",
      "re.findall(pWord,shorttext)\n",
      "522/17:\n",
      "specialtext='U.S.A. poster-print costs $12.40 with 10% off.'\n",
      "re.findall(pWord,specialtext)\n",
      "522/18:\n",
      "pToken=re.compile('(\\w+(-\\w+)*)')\n",
      "re.findall(pToken,specialtext)\n",
      "522/19:\n",
      "# matching Abbrevations\n",
      "pAbbrev=re.compile('(([A-Z]\\.)+)')\n",
      "re.findall(pAbbrev,specialtext)\n",
      "522/20:\n",
      "pToken=re.compile('(\\w+(-\\w+)*|([A-Z]\\.)+)')\n",
      "re.findall(pToken,specialtext)\n",
      "522/21:\n",
      "pToken=re.compile('(([A-Z]\\.)+|\\w+(-\\w+)*)')\n",
      "re.findall(pToken,specialtext)\n",
      "522/22:\n",
      "# Matching currency\n",
      "pToken=re.compile(r'(([A-Z]\\.)+|\\w+(-\\w+)*|\\$?\\d+(\\.\\d+)?)')re.findall(pToken,specialtext)\n",
      "# r -> acceptes \\ as string\n",
      "522/23:\n",
      "# Matching currency\n",
      "pToken=re.compile(r'(([A-Z]\\.)+|\\w+(-\\w+)*|\\$?\\d+(\\.\\d+)?)'\n",
      "re.findall(pToken,specialtext)\n",
      "# r -> acceptes \\ as string\n",
      "522/24:\n",
      "# Matching currency\n",
      "pToken=re.compile(r'(([A-Z]\\.)+|\\w+(-\\w+)*|\\$?\\d+(\\.\\d+)?)')\n",
      "\n",
      "re.findall(pToken,specialtext)\n",
      "# r -> acceptes \\ as string\n",
      "522/25:\n",
      "pToken = re.compile(r'''([A-Z]\\.)+    #abbreviations,e.g.U.S.A.\n",
      "        | \\w+(-\\w+)*                  #wordswithinternalhyphens\n",
      "        | \\$?\\d+(\\.\\d+)?              #currency,like$12.40\n",
      "        ''', re.X)                    #verboseflag\n",
      "522/26:\n",
      "# Built in NLTK tokenizer remove need of paranthessis\n",
      "pattern=r'''(?x)              #set flag to verbose regexp\n",
      "          | ([A-Z]\\.)+        # abbreiviations\n",
      "          | \\w+(-\\w+)*        # words with internal hypthens\n",
      "          | \\$?\\d+(\\.\\d+)?%?  #currencyandpercentages\n",
      "          | \\.\\.\\.            #ellipsis\n",
      "          | [][.,;\"'?():-_']#separatespecialcharactertoken\n",
      "          '''\n",
      "522/27:\n",
      "nltk.regexp_tokenize(shorttext,pattern)\n",
      "nltk.regexp_tokenize(specialtext,pattern)\n",
      "522/28:\n",
      "tweetPattern= r'''(?x)         #set flag to allow verbose regexps\n",
      "| (https?://|www)\\S+         #simpleURLs\n",
      "| (:-\\)|;-\\))                #small list of emoticons\n",
      "| &(amp|lt|gt|quot);         # XML or HTML entity\n",
      "| \\#\\w+                      # hash tags\n",
      "| @\\w+                       # mentions\n",
      "| \\d+:\\d+                    #t ime like pattern\n",
      "| \\d+\\.\\d+                   # number with a decimal\n",
      "| (\\d+,)+?\\d{3}(?=([^,]|$))  # number with a comma\n",
      "| ([A-Z]\\.)+                 # simple abbreviations\n",
      "| (--+)                      # multiple dashes\n",
      "| \\w+(-\\w+)*                 #words with internal hyphens or apostrophes\n",
      "| ['\\\".?!,:;]+               # special characters\n",
      "'''\n",
      "522/29:\n",
      "tweet1=\"@natalieohayreIagree#hc09needsreform-butnotbycrookedpoliticianswhorcluelessabouthealthcare!#tcot#fishyNOGOV'TTAKEOVER!\"\n",
      "\n",
      "tweet2 = \"To Sen. Roland Burris: Affordable, quality health insurance can't waithttp://bit.ly/j63je #hc09 #IL #60660\"\n",
      "\n",
      "tweet3 = \"RT @karoli: RT @Seriou: .@whitehouse I willstand w/ Obama on #healthcare,Itrust him. #p2 #tlot\"\n",
      "522/30: nltk.regexp_tokenize(tweet1,tweetPattern)\n",
      "522/31:\n",
      "tweetPattern= r''' (?x)         #set flag to allow verbose regexps\n",
      "| (https?://|www)\\S+         #simpleURLs\n",
      "| (:-\\)|;-\\))                #small list of emoticons\n",
      "| &(amp|lt|gt|quot);         # XML or HTML entity\n",
      "| \\#\\w+                      # hash tags\n",
      "| @\\w+                       # mentions\n",
      "| \\d+:\\d+                    #t ime like pattern\n",
      "| \\d+\\.\\d+                   # number with a decimal\n",
      "| (\\d+,)+?\\d{3}(?=([^,]|$))  # number with a comma\n",
      "| ([A-Z]\\.)+                 # simple abbreviations\n",
      "| (--+)                      # multiple dashes\n",
      "| \\w+(-\\w+)*                 #words with internal hyphens or apostrophes\n",
      "| ['\\\".?!,:;]+               # special characters\n",
      "'''\n",
      "522/32:\n",
      "tweet1=\"@natalieohayreIagree#hc09needsreform-butnotbycrookedpoliticianswhorcluelessabouthealthcare!#tcot#fishyNOGOV'TTAKEOVER!\"\n",
      "\n",
      "tweet2 = \"To Sen. Roland Burris: Affordable, quality health insurance can't waithttp://bit.ly/j63je #hc09 #IL #60660\"\n",
      "\n",
      "tweet3 = \"RT @karoli: RT @Seriou: .@whitehouse I willstand w/ Obama on #healthcare,Itrust him. #p2 #tlot\"\n",
      "522/33: nltk.regexp_tokenize(tweet1,tweetPattern)\n",
      "522/34:\n",
      "tweet1=\"@natalieohayre I agree #hc09 needs reform- but not by crooked politicians who r clueless about healthcare! #tcot #fishy NO GOV'T TAKEOVER!\"\n",
      "\n",
      "tweet2 = \"To Sen. Roland Burris: Affordable, quality health insurance can't wait http://bit.ly/j63je #hc09 #IL #60660\"\n",
      "\n",
      "tweet3 = \"RT @karoli: RT @Seriou: .@whitehouse I willstand w/ Obama on #healthcare, I trust him. #p2 #tlot\"\n",
      "522/35: nltk.regexp_tokenize(tweet1,tweetPattern)\n",
      "522/36: nltk.regexp_tokenize(tweet2,tweetPattern)\n",
      "522/37:\n",
      "tweet1=\"@natalieohayre I agree #hc09 needs reform- but not by crooked politicians who r clueless about healthcare! #tcot #fishy NO GOV'T TAKEOVER!\"\n",
      "\n",
      "tweet2 = \"To Sen. Roland Burris: Affordable, quality health insurance can't wait http://bit.ly/j63je #hc09 #IL #60660\"\n",
      "\n",
      "tweet3 = \"RT @karoli: RT @Seriou: .@whitehouse I will stand w/ Obama on #healthcare, I trust him. #p2 #tlot\"\n",
      "522/38:\n",
      "tweetPattern= r''' (?x)         #set flag to allow verbose regexps\n",
      "| (https?://|www)\\S+         #simpleURLs\n",
      "| (:-\\)|;-\\))                #small list of emoticons\n",
      "| &(amp|lt|gt|quot);         # XML or HTML entity\n",
      "| \\#\\w+                      # hash tags\n",
      "| @\\w+                       # mentions\n",
      "| \\d+:\\d+                    #t ime like pattern\n",
      "| \\d+\\.\\d+                   # number with a decimal\n",
      "| (\\d+,)+?\\d{3}(?=([^,]|$))  # number with a comma\n",
      "| ([A-Z]\\.)+                 # simple abbreviations\n",
      "| (--+)                      # multiple dashes\n",
      "| \\w+(-\\w+)*                 #words with internal hyphens or apostrophes\n",
      "| ['\\\".?!,:;]+               # special characters\n",
      "'''\n",
      "522/39: nltk.regexp_tokenize(tweet2,tweetPattern)\n",
      "522/40: nltk.regexp_tokenize(tweet3,tweetPattern)\n",
      "522/41: nltk.regexp_tokenize(tweet1,tweetPattern)\n",
      "522/42: nltk.regexp_tokenize(tweet2,tweetPattern)\n",
      "522/43:\n",
      "tweetPattern= r\" (?x)         #set flag to allow verbose regexps\n",
      "| (https?://|www)\\S+         #simpleURLs\n",
      "| (:-\\)|;-\\))                #small list of emoticons\n",
      "| &(amp|lt|gt|quot);         # XML or HTML entity\n",
      "| \\#\\w+                      # hash tags\n",
      "| @\\w+                       # mentions\n",
      "| \\d+:\\d+                    #t ime like pattern\n",
      "| \\d+\\.\\d+                   # number with a decimal\n",
      "| (\\d+,)+?\\d{3}(?=([^,]|$))  # number with a comma\n",
      "| ([A-Z]\\.)+                 # simple abbreviations\n",
      "| (--+)                      # multiple dashes\n",
      "| \\w+(-\\w+)*                 #words with internal hyphens or apostrophes\n",
      "| ['\\\".?!,:;]+               # special characters\n",
      "\"\n",
      "522/44:\n",
      "tweetPattern= r\"\"\" (?x)         #set flag to allow verbose regexps\n",
      "| (https?://|www)\\S+         #simpleURLs\n",
      "| (:-\\)|;-\\))                #small list of emoticons\n",
      "| &(amp|lt|gt|quot);         # XML or HTML entity\n",
      "| \\#\\w+                      # hash tags\n",
      "| @\\w+                       # mentions\n",
      "| \\d+:\\d+                    #t ime like pattern\n",
      "| \\d+\\.\\d+                   # number with a decimal\n",
      "| (\\d+,)+?\\d{3}(?=([^,]|$))  # number with a comma\n",
      "| ([A-Z]\\.)+                 # simple abbreviations\n",
      "| (--+)                      # multiple dashes\n",
      "| \\w+(-\\w+)*                 #words with internal hyphens or apostrophes\n",
      "| ['\\\".?!,:;]+               # special characters\n",
      "\"\"\"\n",
      "522/45:\n",
      "tweet1=\"@natalieohayre I agree #hc09 needs reform- but not by crooked politicians who r clueless about healthcare! #tcot #fishy NO GOV'T TAKEOVER!\"\n",
      "\n",
      "tweet2 = \"To Sen. Roland Burris: Affordable, quality health insurance can't wait http://bit.ly/j63je #hc09 #IL #60660\"\n",
      "\n",
      "tweet3 = \"RT @karoli: RT @Seriou: .@whitehouse I will stand w/ Obama on #healthcare, I trust him. #p2 #tlot\"\n",
      "522/46: nltk.regexp_tokenize(tweet2,tweetPattern)\n",
      "522/47:\n",
      "# Built in NLTK tokenizer remove need of paranthessis\n",
      "pattern=r'''(?x)              #set flag to verbose regexp\n",
      "           (?:[A-Z]\\.)+        # abbreiviations\n",
      "          | \\w+(?:-\\w+)*        # words with internal hypthens\n",
      "          | \\$?\\d+(?:\\.\\d+)?%?  #currency and percentages\n",
      "          | \\.\\.\\.            #ellipsis\n",
      "          | [][.,;\"'?():-_']  #separate special character token\n",
      "          '''\n",
      "522/48:\n",
      "nltk.regexp_tokenize(shorttext,pattern)\n",
      "nltk.regexp_tokenize(specialtext,pattern)\n",
      "522/49:\n",
      "tweetPattern= r\"\"\" (?x)         #set flag to allow verbose regexps\n",
      " (https?://|www)\\S+         #simpleURLs\n",
      "| (:-\\)|;-\\))                #small list of emoticons\n",
      "| &(amp|lt|gt|quot);         # XML or HTML entity\n",
      "| \\#\\w+                      # hash tags\n",
      "| @\\w+                       # mentions\n",
      "| \\d+:\\d+                    #t ime like pattern\n",
      "| \\d+\\.\\d+                   # number with a decimal\n",
      "| (\\d+,)+?\\d{3}(?=([^,]|$))  # number with a comma\n",
      "| (?:[A-Z]\\.)+                 # simple abbreviations\n",
      "| (--+)                      # multiple dashes\n",
      "| \\w+(?:-\\w+)*                 #words with internal hyphens or apostrophes\n",
      "| ['\\\".?!,:;]+               # special characters\n",
      "\"\"\"\n",
      "522/50: nltk.regexp_tokenize(tweet2,tweetPattern)\n",
      "522/51:\n",
      "tweetPattern= r'''(?x)         #set flag to allow verbose regexps\n",
      " (https?://|www)\\S+         #simpleURLs\n",
      "| (:-\\)|;-\\))                #small list of emoticons\n",
      "| &(amp|lt|gt|quot);         # XML or HTML entity\n",
      "| \\#\\w+                      # hash tags\n",
      "| @\\w+                       # mentions\n",
      "| \\d+:\\d+                    #t ime like pattern\n",
      "| \\d+\\.\\d+                   # number with a decimal\n",
      "| (\\d+,)+?\\d{3}(?=([^,]|$))  # number with a comma\n",
      "| (?:[A-Z]\\.)+                 # simple abbreviations\n",
      "| (--+)                      # multiple dashes\n",
      "| \\w+(?:-\\w+)*                 #words with internal hyphens or apostrophes\n",
      "| ['\\\".?!,:;]+               # special characters\n",
      "'''\n",
      "522/52:\n",
      "tweet1=\"@natalieohayre I agree #hc09 needs reform- but not by crooked politicians who r clueless about healthcare! #tcot #fishy NO GOV'T TAKEOVER!\"\n",
      "\n",
      "tweet2 = \"To Sen. Roland Burris: Affordable, quality health insurance can't wait http://bit.ly/j63je #hc09 #IL #60660\"\n",
      "\n",
      "tweet3 = \"RT @karoli: RT @Seriou: .@whitehouse I will stand w/ Obama on #healthcare, I trust him. #p2 #tlot\"\n",
      "522/53: nltk.regexp_tokenize(tweet2,tweetPattern)\n",
      "522/54:\n",
      "tweetPattern= r'''(?x)         #set flag to allow verbose regexps\n",
      " (https?://|www)\\S+         #simpleURLs\n",
      "| (:-\\)|;-\\))                #small list of emoticons\n",
      "| &(amp|lt|gt|quot);         # XML or HTML entity\n",
      "| \\#\\w+                      # hash tags\n",
      "| @\\w+                       # mentions\n",
      "| \\d+:\\d+                    #t ime like pattern\n",
      "| \\d+\\.\\d+                   # number with a decimal\n",
      "| (?:\\d+,)+?\\d{3}(?=([^,]|$))  # number with a comma\n",
      "| (?:[A-Z]\\.)+                 # simple abbreviations\n",
      "| (--+)                      # multiple dashes\n",
      "| \\w+(?:-\\w+)*                 #words with internal hyphens or apostrophes\n",
      "| ['\\\".?!,:;]+               # special characters\n",
      "'''\n",
      "522/55:\n",
      "tweet1=\"@natalieohayre I agree #hc09 needs reform- but not by crooked politicians who r clueless about healthcare! #tcot #fishy NO GOV'T TAKEOVER!\"\n",
      "\n",
      "tweet2 = \"To Sen. Roland Burris: Affordable, quality health insurance can't wait http://bit.ly/j63je #hc09 #IL #60660\"\n",
      "\n",
      "tweet3 = \"RT @karoli: RT @Seriou: .@whitehouse I will stand w/ Obama on #healthcare, I trust him. #p2 #tlot\"\n",
      "522/56: nltk.regexp_tokenize(tweet2,tweetPattern)\n",
      "522/57:\n",
      "tweetPattern= r'''(?x)         #set flag to allow verbose regexps\n",
      " (https?://|www)\\S+         #simpleURLs\n",
      "| (:-\\)|;-\\))                #small list of emoticons\n",
      "| &(amp|lt|gt|quot);         # XML or HTML entity\n",
      "| (?:[A-Z]\\.)+               # abbreviations\n",
      "| [\\w']+                     # can't\n",
      "| \\#\\w+                      # hash tags\n",
      "| @\\w+                       # mentions\n",
      "| \\d+:\\d+                    #t ime like pattern\n",
      "| \\d+\\.\\d+                   # number with a decimal\n",
      "| (?:\\d+,)+?\\d{3}(?=([^,]|$))  # number with a comma\n",
      "| (?:[A-Z]\\.)+                 # simple abbreviations\n",
      "| (--+)                      # multiple dashes\n",
      "| \\w+(?:-\\w+)*                 #words with internal hyphens or apostrophes\n",
      "| ['\\\".?!,:;]+               # special characters\n",
      "'''\n",
      "522/58:\n",
      "tweet1=\"@natalieohayre I agree #hc09 needs reform- but not by crooked politicians who r clueless about healthcare! #tcot #fishy NO GOV'T TAKEOVER!\"\n",
      "\n",
      "tweet2 = \"To Sen. Roland Burris: Affordable, quality health insurance can't wait http://bit.ly/j63je #hc09 #IL #60660\"\n",
      "\n",
      "tweet3 = \"RT @karoli: RT @Seriou: .@whitehouse I will stand w/ Obama on #healthcare, I trust him. #p2 #tlot\"\n",
      "522/59: nltk.regexp_tokenize(tweet2,tweetPattern)\n",
      "540/1: _ih[-15:]\n",
      "540/2: %history -g\n",
      "540/3: .ipynb_checkpoints/\n",
      "540/4: %.ipynb_checkpoints/\n",
      "540/5: %history -g -f notebook_file.ipynb\n",
      "541/1: %history -g -f notebook_file.ipynb\n",
      "541/2: %history -g\n",
      "541/3: %history -g -f notebook_file.ipynb\n",
      "   1: %history -g\n"
     ]
    }
   ],
   "source": [
    "%history -g"
   ]
  }
 ]
}