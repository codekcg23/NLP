{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python376jvsc74a57bd0fbbb7d2143a1d68e1cf272edf0974e702b621cb99b4ee39ce84db3bf0ffb588e",
   "display_name": "Python 3.7.6 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "## Activity 1"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "*** Introductory Examples for the NLTK Book ***\n",
      "Loading text1, ..., text9 and sent1, ..., sent9\n",
      "Type the name of the text or sentence to view it.\n",
      "Type: 'texts()' or 'sents()' to list the materials.\n",
      "text1: Moby Dick by Herman Melville 1851\n",
      "text2: Sense and Sensibility by Jane Austen 1811\n",
      "text3: The Book of Genesis\n",
      "text4: Inaugural Address Corpus\n",
      "text5: Chat Corpus\n",
      "text6: Monty Python and the Holy Grail\n",
      "text7: Wall Street Journal\n",
      "text8: Personals Corpus\n",
      "text9: The Man Who Was Thursday by G . K . Chesterton 1908\n"
     ]
    }
   ],
   "source": [
    "from nltk.book import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['The',\n",
       " 'family',\n",
       " 'of',\n",
       " 'Dashwood',\n",
       " 'had',\n",
       " 'long',\n",
       " 'been',\n",
       " 'settled',\n",
       " 'in',\n",
       " 'Sussex',\n",
       " '.']"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "# 1.list of tokens of the first sentence of Sense and Sensibility by Jane Austen\n",
    "sent2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Largest text: <Text: Moby Dick by Herman Melville 1851> 260819\nsmallest text: <Text: Personals Corpus> 4867\n"
     ]
    }
   ],
   "source": [
    "# 2.largest and the smallest of these texts.\n",
    "text_len = {}\n",
    "for t in [text1,text2,text3,text4,text5,text6,text7,text8,text9]:\n",
    "    text_len[t]=len(t)\n",
    "print(\"Largest text:\",max(text_len,key = text_len.get),\" \", max(text_len.values()))\n",
    "print(\"smallest text:\",min(text_len,key = text_len.get),\" \", min(text_len.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "2789"
      ]
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "source": [
    "# 3. Number of Unique word in The book of Gensis\n",
    "len(set(text3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "room box word case clients band music favorite ps\n"
     ]
    }
   ],
   "source": [
    "# 4. find in Chat corpus\n",
    "text5.similar(\"world\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Displaying 9 of 9 matches:\nrom work great night LOL It is in my world hi U37 ooppsss BOOTS Well , the hand\nmay I ?? every day is tuesday in his world anyone wanna chat i dont like you U2\nehe snort snort hahahaha . The whole world ? lol I really recomend getting the \n 1 / 2 year old daughter . she 's my world .. Hi U19 U58 ! JOIN <--- U64 may i \nr here , first the Cardnials win the World Series , and then .......... well la\nn used for that ? welcome to da real world ever hear of Zyban ? Ummm are you ta\narlie manson ?? which one ? PART the world may never know ... hi everybody !!..\nsingle man to take the power trippin world in his hand * U53 where are you ? Ye\ny .. it 's really boring in the real world . . ACTION pokkies U34 >.>-> ( o.o )\n"
     ]
    }
   ],
   "source": [
    "text5.concordance(\"world\")"
   ]
  },
  {
   "source": [
    "## Activity 2"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['austen-emma.txt',\n",
       " 'austen-persuasion.txt',\n",
       " 'austen-sense.txt',\n",
       " 'bible-kjv.txt',\n",
       " 'blake-poems.txt',\n",
       " 'bryant-stories.txt',\n",
       " 'burgess-busterbrown.txt',\n",
       " 'carroll-alice.txt',\n",
       " 'chesterton-ball.txt',\n",
       " 'chesterton-brown.txt',\n",
       " 'chesterton-thursday.txt',\n",
       " 'edgeworth-parents.txt',\n",
       " 'melville-moby_dick.txt',\n",
       " 'milton-paradise.txt',\n",
       " 'shakespeare-caesar.txt',\n",
       " 'shakespeare-hamlet.txt',\n",
       " 'shakespeare-macbeth.txt',\n",
       " 'whitman-leaves.txt']"
      ]
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "source": [
    "# 1. books in Guternberg Corpus\n",
    "import nltk\n",
    "nltk.corpus.gutenberg.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "austen-emma.txt  has richness 24.63538599411087\n",
      "austen-persuasion.txt  has richness 16.00962165688193\n",
      "austen-sense.txt  has richness 20.719449729255086\n",
      "bible-kjv.txt  has richness 73.40068269300603\n",
      "blake-poems.txt  has richness 4.59010989010989\n",
      "bryant-stories.txt  has richness 12.57081447963801\n",
      "burgess-busterbrown.txt  has richness 10.75\n",
      "carroll-alice.txt  has richness 11.309681697612731\n",
      "chesterton-ball.txt  has richness 10.841175813121717\n",
      "chesterton-brown.txt  has richness 10.37028557657549\n",
      "chesterton-thursday.txt  has richness 10.167915381225209\n",
      "edgeworth-parents.txt  has richness 21.960075054727405\n",
      "melville-moby_dick.txt  has richness 13.502044830977896\n",
      "milton-paradise.txt  has richness 9.00613896381732\n",
      "shakespeare-caesar.txt  has richness 7.256460674157303\n",
      "shakespeare-hamlet.txt  has richness 6.858821369561227\n",
      "shakespeare-macbeth.txt  has richness 5.760517799352751\n",
      "whitman-leaves.txt  has richness 10.809058552585665\n"
     ]
    }
   ],
   "source": [
    "# method 1\n",
    "for file in nltk.corpus.gutenberg.fileids():\n",
    "    text = nltk.corpus.gutenberg.raw(file)\n",
    "    #print(len(set(text)))\n",
    "    richness = len(nltk.wordpunct_tokenize(text))/len(set(nltk.wordpunct_tokenize(text)))\n",
    "    print(file,\" has richness\",richness )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[24.63538599411087,\n",
       " 16.00962165688193,\n",
       " 20.719449729255086,\n",
       " 73.40068269300603,\n",
       " 4.59010989010989,\n",
       " 12.57081447963801,\n",
       " 10.75,\n",
       " 11.309681697612731,\n",
       " 10.841175813121717,\n",
       " 10.37028557657549,\n",
       " 10.167915381225209,\n",
       " 21.960075054727405,\n",
       " 13.502044830977896,\n",
       " 9.00613896381732,\n",
       " 7.256460674157303,\n",
       " 6.858821369561227,\n",
       " 5.760517799352751,\n",
       " 10.809058552585665]"
      ]
     },
     "metadata": {},
     "execution_count": 48
    }
   ],
   "source": [
    "# method 2\n",
    "richness = [len(gutenberg.words(book)) / len(set(gutenberg.words(book))) for book in nltk.corpus.gutenberg.fileids()]\n",
    "richness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "news = \"\"\"If Joe Biden was hoping for what he called a significant de-escalation in the conflict, he hasn’t got it yet. BBC colleagues in Gaza reported a long night of bombardment, from air and sea.\n",
    "\n",
    "But there was an eight-hour lull in rocket attacks from Hamas, which could be seen as a step on President Biden’s “road to a ceasefire”.\n",
    "\n",
    "Hamas officials sound confident that the fighting could end in the next day or two.\n",
    "\n",
    "Rhetorically, at least, that’s not the impression Israel wants to give. Expect to hear more talk of an operation continuing at “full throttle”, with plenty of targets left to hit.\n",
    "\n",
    "After speaking to President Biden yesterday, Prime Minister Benjamin Netanyahu said he was “determined to continue this operation until its goal is achieved - to restore peace and security to you, the citizens of Israel\".\n",
    "\n",
    "But the clock is clearly ticking. The Biden administration has signalled its impatience.\n",
    "\n",
    "As they prepare to call a halt soon, Israeli officials are putting a positive gloss on the operation so far.\n",
    "\n",
    "They say they’ve achieved more in the past 10 days than they did in seven weeks in 2014, without needing to send troops in on the ground.\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1.5562913907284768"
      ]
     },
     "metadata": {},
     "execution_count": 51
    }
   ],
   "source": [
    "\n",
    "#news_richness = len(news_list)/len(set(news_list))\n",
    "news_richness= len(nltk.wordpunct_tokenize(news))/len(set(nltk.wordpunct_tokenize(news)))\n",
    "news_richness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<Text: Moby Dick by Herman Melville 1851>   0.004600891806195101\n<Text: Sense and Sensibility by Jane Austen 1811>   0.058625755777815446\n<Text: The Book of Genesis>   0.0\n<Text: Inaugural Address Corpus>   0.01668925278877414\n<Text: Chat Corpus>   0.026660742057320597\n<Text: Monty Python and the Holy Grail>   0.0\n<Text: Wall Street Journal>   0.020858993205927927\n<Text: Personals Corpus>   0.061639613725087326\n<Text: The Man Who Was Thursday by G . K . Chesterton 1908>   0.0057792611214656205\n"
     ]
    }
   ],
   "source": [
    "# the percentage of the number of occurrences of the word “family” in each text.\n",
    "for text in [text1,text2,text3,text4,text5,text6,text7,text8,text9]:\n",
    "    print(text,\" \",(text.count(\"family\")/ len(text))*100)"
   ]
  },
  {
   "source": [
    "## Activity 3"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'austen-persuasion.txt'"
      ]
     },
     "metadata": {},
     "execution_count": 48
    }
   ],
   "source": [
    "file1 = nltk.corpus.gutenberg.fileids()[1]\n",
    "file1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'-', '.', 'a', 'e', 'i', 'n', 'o', 'p', 'r', 's', 't', 'u', 'x'}"
      ]
     },
     "metadata": {},
     "execution_count": 44
    }
   ],
   "source": [
    "#set(file1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['[', 'Persuasion', 'by', 'Jane', 'Austen', '1818', ']', 'Chapter', '1', 'Sir']"
      ]
     },
     "metadata": {},
     "execution_count": 51
    }
   ],
   "source": [
    "austentext = nltk.corpus.gutenberg.raw(file1)\n",
    "tokens =nltk.wordpunct_tokenize(austentext)\n",
    "tokens[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['[', 'persuasion', 'by', 'jane', 'austen', '1818', ']', 'chapter', '1', 'sir']"
      ]
     },
     "metadata": {},
     "execution_count": 53
    }
   ],
   "source": [
    "austenwords = [w.lower( ) for w in tokens]\n",
    "austenwords[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['abilities',\n",
       " 'able',\n",
       " 'abode',\n",
       " 'abominable',\n",
       " 'abominate',\n",
       " 'abominates',\n",
       " 'about',\n",
       " 'above',\n",
       " 'abroad',\n",
       " 'absence',\n",
       " 'absent',\n",
       " 'absenting',\n",
       " 'absolute',\n",
       " 'absolutely',\n",
       " 'abstraction',\n",
       " 'absurd',\n",
       " 'absurdity',\n",
       " 'abundance',\n",
       " 'abuse',\n",
       " 'abused',\n",
       " 'abydos',\n",
       " 'accent',\n",
       " 'accept',\n",
       " 'acceptable',\n",
       " 'acceptance',\n",
       " 'accepted',\n",
       " 'accepting',\n",
       " 'accession',\n",
       " 'accessions',\n",
       " 'accident',\n",
       " 'accidental',\n",
       " 'accidentally',\n",
       " 'accommodate',\n",
       " 'accommodating',\n",
       " 'accommodation',\n",
       " 'accommodations',\n",
       " 'accompanied',\n",
       " 'accompany',\n",
       " 'accompanying',\n",
       " 'accomplish',\n",
       " 'accomplished',\n",
       " 'accomplishment',\n",
       " 'accomplishments',\n",
       " 'accord',\n",
       " 'according',\n",
       " 'accordingly',\n",
       " 'accosted',\n",
       " 'account',\n",
       " 'accounts',\n",
       " 'accurately']"
      ]
     },
     "metadata": {},
     "execution_count": 60
    }
   ],
   "source": [
    "vocab = sorted(set(austenwords))\n",
    "vocab[100:150]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "452301"
      ]
     },
     "metadata": {},
     "execution_count": 68
    }
   ],
   "source": [
    "austentext.rfind(\"author\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'a'"
      ]
     },
     "metadata": {},
     "execution_count": 70
    }
   ],
   "source": [
    "austentext[austentext.rfind(\"author\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "388618"
      ]
     },
     "metadata": {},
     "execution_count": 69
    }
   ],
   "source": [
    "austentext.rfind(\"title\")"
   ]
  }
 ]
}