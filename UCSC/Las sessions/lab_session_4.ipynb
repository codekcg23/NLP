{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.6 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "fbbb7d2143a1d68e1cf272edf0974e702b621cb99b4ee39ce84db3bf0ffb588e"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Lab Session 4\n",
    "\n",
    "Index Number - 17000475"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "source": [
    "## Question 1"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{Happy} {Birthday} 23 23{a}\n{H}{A}{P}{P}{Y} birthday 23 a{A} {Apple}\npeople {pet} {put} {pet}t p\n23 23. {23.5} {23.55}\n{}a{ ap}{}p{le }{}e{ye no noh}{} {}p{}o{}o{}\n{word} {apple} {apple} {23} {a}\n{aaa} apple an {eeee} e {ee} {eeeee}e\n"
     ]
    }
   ],
   "source": [
    "# Question 1\n",
    "#a) \n",
    "regex_a= \"[a-zA-Z]+\"\n",
    "# All alphabatic chracterc including upper and lowercases\n",
    "nltk.re_show(regex_a,\"Happy Birthday 23 23a\")\n",
    "\n",
    "#b) First letter starting with uppercase followinf by 0 or more lower cases\n",
    "regex_b  = \"[A-Z][a-z]*\"\n",
    "nltk.re_show(regex_b,\"HAPPY birthday 23 aA Apple \")\n",
    "\n",
    "# c) words starting form letter p following vowels then following t letter.\n",
    "regex_c = \"p[aeiou]{,2}t\"\n",
    "\n",
    "nltk.re_show(regex_c,\"people pet put pett p\" )\n",
    "# d) Digits with decimal notation 0 or more.\n",
    "regex_d = \"\\d+(\\.\\d+)\"\n",
    "nltk.re_show(regex_d,\"23 23. 23.5 23.55\")\n",
    "\n",
    "#e) empty string or  starting with vowel middle letter is vowel but  ending with vowel or empty string\n",
    "regex_e = \"([^aeiou][aeiou][^aeiou])*\"\n",
    "nltk.re_show(regex_e,\"a apple eye no noh poo\")\n",
    "\n",
    "#f) splitting words by space\n",
    "regex_f = \"\\w+|[^\\w\\s]+\"\n",
    "nltk.re_show(regex_f,\"word apple apple 23 a\")\n",
    "\n",
    "#g) words with only vowel letters from 2 to 5\n",
    "regex_g = \"[aeiou]{2,5}\"\n",
    "nltk.re_show(regex_g,\"aaa apple an eeee e ee eeeeee\")"
   ]
  },
  {
   "source": [
    "## Question 2"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{a} {a}pple {an} {the} houe\n{3*4+9}\n"
     ]
    }
   ],
   "source": [
    "# a)\n",
    "regex_determiner = \"(an|a|the)\"\n",
    "nltk.re_show(regex_determiner,\"a apple an the houe\")\n",
    "\n",
    "# b) \n",
    "regex_arithmatic = \"([-+]?[0-9]*\\.?[0-9]+[\\/\\+\\-\\*])+([-+]?[0-9]*\\.?[0-9]+)\"\n",
    "nltk.re_show(regex_arithmatic,\"3*4+9\")"
   ]
  },
  {
   "source": [
    "## Question 3"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['As',\n",
       " 'our',\n",
       " 'computing',\n",
       " 'resources',\n",
       " 'and',\n",
       " 'modeling',\n",
       " 'capabilities',\n",
       " 'grow',\n",
       " ',',\n",
       " 'so',\n",
       " 'does',\n",
       " 'our',\n",
       " 'potential',\n",
       " 'to',\n",
       " 'support',\n",
       " 'healthy',\n",
       " 'conversations',\n",
       " 'across',\n",
       " 'the',\n",
       " 'globe',\n",
       " '.',\n",
       " 'Develop',\n",
       " 'strategies',\n",
       " 'to',\n",
       " 'build',\n",
       " 'effective',\n",
       " 'multilingual',\n",
       " 'models',\n",
       " 'and',\n",
       " 'you',\n",
       " \"'\",\n",
       " 'll',\n",
       " 'help',\n",
       " 'Conversation',\n",
       " 'AI',\n",
       " 'and',\n",
       " 'the',\n",
       " 'entire',\n",
       " 'industry',\n",
       " 'realize',\n",
       " 'that',\n",
       " 'potential',\n",
       " '.']"
      ]
     },
     "metadata": {},
     "execution_count": 40
    }
   ],
   "source": [
    "article = \"As our computing resources and modeling capabilities grow, so does our potential to support healthy conversations across the globe. Develop strategies to build effective multilingual models and you'll help Conversation AI and the entire industry realize that potential.\"\n",
    "#a\n",
    "# Built in NLTK tokenizer remove need of paranthessis\n",
    "pattern=r'''(?x)                #set flag to verbose regexp\n",
    "           (?:[A-Z]\\.)+         # abbreiviations\n",
    "          | \\w+(?:-\\w+)*        # words with internal hypthens\n",
    "          | \\$?\\d+(?:\\.\\d+)?%?  #currency and percentages\n",
    "          | \\.\\.\\.              #ellipsis\n",
    "          | [][.,;\"'?():-_']    #separate special character token\n",
    "          '''\n",
    "nltk.regexp_tokenize(article,pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['$25', '25%']"
      ]
     },
     "metadata": {},
     "execution_count": 89
    }
   ],
   "source": [
    "# b)\n",
    "#i) monetary amounts\n",
    "nltk.regexp_tokenize('$25 25%',r'''\\$?\\d+(?:\\.\\d+)?%?''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['23/0/2021']"
      ]
     },
     "metadata": {},
     "execution_count": 93
    }
   ],
   "source": [
    "# ii) dates\n",
    "nltk.regexp_tokenize(\" 23/0/2021 \",r'''[0-9]{,2}/[0-9]{,2}/[0-9]{4}''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['As', 'Develop', 'Conversation', 'A', 'I']"
      ]
     },
     "metadata": {},
     "execution_count": 57
    }
   ],
   "source": [
    "# iii) People and organizations\n",
    "nltk.regexp_tokenize(article, r'''[A-Z][a-z]*''')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "metadata": {},
     "execution_count": 53
    }
   ],
   "source": [
    "nltk.regexp_tokenize(\" 23/0/2021\",r'''[0-9]{2}/[0-9]{2}/[0-9]{4}''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['As', 'Develop', 'Conversation', 'A', 'I']"
      ]
     },
     "metadata": {},
     "execution_count": 50
    }
   ],
   "source": [
    "#c) capitalized words\n",
    "nltk.regexp_tokenize(article, r'''[A-Z][a-z]*''')"
   ]
  },
  {
   "source": [
    "## Question 4\n",
    "\n",
    "Collocations - Expressions containing multiple words ex _: new york\n",
    "\n",
    "There are most common two types of Collocations bigrams and trigrams\n",
    "\n",
    "Bigrams - Sequence of two adjasent elements from a string of tokens"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.book import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a\n",
    "from nltk.book import *\n",
    "from nltk.collocations import *\n",
    "from nltk.collocations import BigramCollocationFinder\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "source": [],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['wanna chat',\n",
       " 'PART JOIN',\n",
       " 'MODE #14-19teens',\n",
       " 'JOIN PART',\n",
       " 'PART PART',\n",
       " 'cute.-ass MP3',\n",
       " 'MP3 player',\n",
       " 'JOIN JOIN',\n",
       " 'times .. .',\n",
       " 'ACTION watches',\n",
       " 'guys wanna',\n",
       " 'song lasts',\n",
       " 'last night',\n",
       " 'ACTION sits',\n",
       " '-...)...- S.M.R.',\n",
       " 'Lime Player',\n",
       " 'Player 12%',\n",
       " 'dont know',\n",
       " 'lez gurls',\n",
       " 'long time']"
      ]
     },
     "metadata": {},
     "execution_count": 87
    }
   ],
   "source": [
    "text5.collocation_list()\n",
    "# Apparently it looks like collocations() is buggy and this was the solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['million *U*',\n",
       " 'New York',\n",
       " 'billion *U*',\n",
       " 'Wall Street',\n",
       " 'program trading',\n",
       " 'Mrs. Yeargin',\n",
       " 'vice president',\n",
       " 'Stock Exchange',\n",
       " 'Big Board',\n",
       " 'Georgia Gulf',\n",
       " 'chief executive',\n",
       " 'Dow Jones',\n",
       " 'S&P 500',\n",
       " 'says *T*-1',\n",
       " 'York Stock',\n",
       " 'last year',\n",
       " 'Sea Containers',\n",
       " 'South Korea',\n",
       " 'American Express',\n",
       " 'San Francisco']"
      ]
     },
     "metadata": {},
     "execution_count": 86
    }
   ],
   "source": [
    "text7.collocation_list()"
   ]
  },
  {
   "source": [
    "## Question 5"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "#a) IPA for Sinhala\n",
    "#Kavishka\n",
    "IPA = 'kʌ vi: ʃʌ kɑː'\n",
    "\n",
    "#b)\n",
    "# i) \n",
    "University = '/junəˈvɝsəti/'\n",
    "# ii) \n",
    "Computer = '/kəmˈpjutɝ/'\n",
    "# iii) \n",
    "Information = '/ɪnfɝˈmeɪʃən/'"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ]
}